{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxr5psdq/96v8dZ7Ycmk7e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/almutareb/huggingface-nlp-demo/blob/main/intro_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ü§ó Transformers library provides the functionality to create and use those shared models. The Model Hub contains thousands of pretrained models that anyone can download and use."
      ],
      "metadata": {
        "id": "w9BJ1VproKQ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2GhBNLoiBn0"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most basic object in the ü§ó Transformers library is the pipeline() function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer:"
      ],
      "metadata": {
        "id": "_grTs88np4gH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"I've been waiting for a HuggingFace course my whole life\")"
      ],
      "metadata": {
        "id": "PeIVaDMJjlXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\n",
        "    [\"I've been waiting for a HuggingFace course for a very long time.\", \"I hate this so much\"]\n",
        ")"
      ],
      "metadata": {
        "id": "Nn--oOtIjpYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, this pipeline selects a particular pretrained model that has been fine-tuned for sentiment analysis in English. The model is downloaded and cached when you create the classifier object. If you rerun the command, the cached model will be used instead and there is no need to download the model again.\n",
        "\n",
        "There are three main steps involved when you pass some text to a pipeline:\n",
        "\n",
        "    1.   The text is preprocessed into a format the model can understand\n",
        "    2.   The preprocessed inputs are passed to the model.\n",
        "    3.   The predictions of the model are post-processed, so you can make sense of them."
      ],
      "metadata": {
        "id": "uT2PN3RUqY8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of the currently available pipelines are:\n",
        "\n",
        "*    feature-extraction (get the vector representation of a text)\n",
        "*    fill-mask\n",
        "*    ner (named entity recognition)\n",
        "*    question-answering\n",
        "*    sentiment-analysis\n",
        "*    summarization\n",
        "*    text-generation\n",
        "*    translation\n",
        "*    zero-shot-classification"
      ],
      "metadata": {
        "id": "T8U9VCv0qwBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-Shot Classification"
      ],
      "metadata": {
        "id": "WjrAvhfX2sOf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The zero-shot-classification pipeline is very powerful: it allows you to specify which labels to use for the classification, so you don‚Äôt have to rely on the labels of the pretrained model."
      ],
      "metadata": {
        "id": "scygXvdGsIt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"This is a course about the Transformation library\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")"
      ],
      "metadata": {
        "id": "2m5JX2T4j3nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pipeline is called zero-shot because you don‚Äôt need to fine-tune the model on your data to use it. It can directly return probability scores for any list of labels you want!"
      ],
      "metadata": {
        "id": "PTsx-ENMsYPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"In this course, we will teach you how to\",\n",
        "          num_return_sequences=3,\n",
        "          max_length=35,\n",
        "          )"
      ],
      "metadata": {
        "id": "JJ4gDz4CsdaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The previous examples used the default model for the task at hand, but you can also choose a particular model from the Hub to use in a pipeline for a specific task"
      ],
      "metadata": {
        "id": "d_-UOnuLuxix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text generation"
      ],
      "metadata": {
        "id": "2rbrPHUy24yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ],
      "metadata": {
        "id": "hIiNw2Szu1hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mask filling"
      ],
      "metadata": {
        "id": "C4JB37xR2zyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-cased\")\n",
        "unmasker(\"This course will each you all about [MASK] models.\", top_k=2)"
      ],
      "metadata": {
        "id": "NSydumI-v6ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top_k argument controls how many possibilities you want to be displayed. Note that here the model fills in the special \\[MASK] word, which is often referred to as a mask token. Other mask-filling models might have different mask tokens, so it‚Äôs always good to verify the proper mask word when exploring other models. One way to check it is by looking at the mask word used in the widget."
      ],
      "metadata": {
        "id": "CtCLMMCd1zwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Name entity recognition"
      ],
      "metadata": {
        "id": "1GLq4UrC2rIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Sylvester James Pussycat and I work at Warner Bros in Florida.\")"
      ],
      "metadata": {
        "id": "GoqJVDDl2FIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question answering"
      ],
      "metadata": {
        "id": "SUNMoJIB5alu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"Where do I work?\",\n",
        "    context=\"My name is Sylvester James Pussycat and I work at Warner Bros in Florida.\",\n",
        ")"
      ],
      "metadata": {
        "id": "o4vrRBAw5dBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarizatrion"
      ],
      "metadata": {
        "id": "WhSPmW7I5zIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Pipeline\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    Robotic process automation (RPA) is a form of business process automation that is based on software robots (bots) or artificial intelligence (AI) agents.[1] It is sometimes referred to as software robotics (not to be confused with robot software).\n",
        "In traditional workflow automation tools, a software developer produces a list of actions to automate a task and interface to the back end system using internal application programming interfaces (APIs) or dedicated scripting language. In contrast, RPA systems develop the action list by watching the user perform that task in the application's graphical user interface (GUI), and then perform the automation by repeating those tasks directly in the GUI. This can lower the barrier to the use of automation in products that might not otherwise feature APIs for this purpose.\n",
        "RPA tools have strong technical similarities to graphical user interface testing tools. These tools also automate interactions with the GUI, and often do so by repeating a set of demonstration actions performed by a user. RPA tools differ from such systems in that they allow data to be handled in and between multiple applications, for instance, receiving email containing an invoice, extracting the data, and then typing that into a bookkeeping system.\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "717BMeJ451XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation"
      ],
      "metadata": {
        "id": "sizrKoNK6i8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "translator(\"Cela semble tr√®s bien fonctionner\")"
      ],
      "metadata": {
        "id": "zi1lHUhl6lWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bias and limitations"
      ],
      "metadata": {
        "id": "wnG8mnpQHuSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your intent is to use a pretrained model or a fine-tuned version in production, please be aware that, while these models are powerful tools, they come with limitations. The biggest of these is that, to enable pretraining on large amounts of data, researchers often scrape all the content they can find, taking the best as well as the worst of what is available on the internet."
      ],
      "metadata": {
        "id": "dhlMFV7NIOun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "result = unmasker(\"This man works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"This woman works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbh00PfQHxbb",
        "outputId": "829f54a6-6a56-4abb-ebac-5f0d164af233"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['carpenter', 'lawyer', 'farmer', 'businessman', 'doctor']\n",
            "['nurse', 'maid', 'teacher', 'waitress', 'prostitute']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When asked to fill in the missing word in these two sentences, prostitute ended up in the top 5 possibilities the model associates with ‚Äúwoman‚Äù and ‚Äúwork.‚Äù\n",
        "This happens even though BERT is one of the rare Transformer models not built by scraping data from all over the internet, but rather using apparently neutral data (it‚Äôs trained on the English Wikipedia and BookCorpus datasets).\n",
        "\n",
        "When you use these tools, you therefore need to keep in the back of your mind that the original model you are using could very easily generate sexist, racist, or homophobic content. Fine-tuning the model on your data won‚Äôt make this intrinsic bias disappear."
      ],
      "metadata": {
        "id": "jyAm0yAHIcz0"
      }
    }
  ]
}